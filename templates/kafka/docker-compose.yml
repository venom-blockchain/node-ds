version: '2.3'
services:
  kafka:
    image: confluentinc/cp-kafka:7.6.0-2-ubi8.amd64
    restart: unless-stopped
    expose:
      - "9092"
      - "29092"
    networks:
      - {{NETWORK}}
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://kafka:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9581
      KAFKA_LOG_RETENTION_HOURS: 4
      KAFKA_LOG_ROLL_MS: 600000
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_CLEANUP_POLICY: delete
      KAFKA_RETENTION_MS: 43200000
      KAFKA_MESSAGE_MAX_BYTES: 40000000
      KAFKA_RECEIVE_MESSAGE_MAX_BYTES: 40000000
      KAFKA_REPLICA_FETCH_MAX_BYTES: 40000000
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      CLUSTER_ID: MkU3OEVBXVcwNTJENDM2Qk
    volumes:
      - data:/var/lib/kafka/data
    mem_limit: {{KAFKA_MEMORY}}
  connect:
    image: confluentinc/cp-kafka-connect:7.6.0-2-ubi8.amd64
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Assumes image is based on confluentinc/kafka-connect-datagen:latest which is pulling 7.6.0 Connect image
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.6.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      KAFKA_JMX_PORT: 9584
      CONNECT_FETCH_MESSAGE_MAX_BYTES: 40010000
      CONNECT_MAX_REQUEST_SIZE: 40010000
      # https://docs.confluent.io/platform/7.3/installation/configuration/consumer-configs.html#fetch-max-bytes
      CONNECT_MAX_PARTITION_FETCH_BYTES: 40010000
      CLUSTER_ID: MkU3OEVBXVcwNTJENDM2Qk
    networks:
      - {{NETWORK}}
    volumes:
      - ./files/kafka-connect-arangodb:/usr/share/java/kafka-connect-arangodb
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://connect:8083/"]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 60s
    mem_limit: {{CONNECT_MEMORY}}

  check-connect:
    build:
      context: build_check
    restart: unless-stopped
    depends_on:
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "/work/check.sh http://connect:8083/connectors"]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 120s
    networks:
      - {{NETWORK}}

networks:
  {{NETWORK}}:
    external: true

volumes:
  data:
  zk_log:
  zk_data:
